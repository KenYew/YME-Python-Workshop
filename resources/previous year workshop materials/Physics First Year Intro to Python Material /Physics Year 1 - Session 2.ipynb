{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Physics Year 1 - Session 2.ipynb","version":"0.3.2","provenance":[{"file_id":"13I5ju-BtGW_IEc5O2S_4rk191PUEsOzb","timestamp":1547647541445}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"nLtD30Cl82pu","colab_type":"text"},"cell_type":"markdown","source":["# Session 2"]},{"metadata":{"id":"xjjxHKTF82pw","colab_type":"text"},"cell_type":"markdown","source":["## Index\n","\n","1. [Intended learning outcomes](#outcomes)\n","2. [Plotting and array statistics - recap](#recap)\n","3. [Plotting error bars](#errorbars)\n","4. [Line fitting](#linefitting)\n","5. [Non-linear fits](#nonlinear)\n"]},{"metadata":{"id":"8y007fRS82px","colab_type":"text"},"cell_type":"markdown","source":["## 1. Intended learning outcomes<a id=\"outcomes\"></a>\n","After this session, you should be able to:\n","- plot error bars on scatter plots;\n","- fit a polynomial of any order to your data and plot the fit with your data;\n","- find the uncertainties on your fit parameters;\n","- create and interpret a residuals plot;\n","- fit non-linear functions to your data;\n","- combine two fitting functions to fit your data."]},{"metadata":{"id":"hMkNZwDX82py","colab_type":"text"},"cell_type":"markdown","source":["## 2. Plotting and array statistics - recap<a id=\"recap\"></a>\n","In this section, we will analyze five sets of data, each having 20 points. These numbers have been generated using a random number generator, and are all drawn from a normal distribution with the same mean and standard deviation. We will plot the histograms of the data sets and calculate their mean, standard deviation, and standard error of the mean.\n","\n","** Exercise 1: before you move on, make sure to import the relevant packages below. Which will you need for this section?**"]},{"metadata":{"id":"5uMTRv_W82pz","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"KXyMxq6v82p2","colab_type":"text"},"cell_type":"markdown","source":["Now we are ready to carry on. \n","\n","**Exercise 2: read the data stored in the file [five_datasets.txt](five_datasets.txt) into Python. Next, for each dataset, plot a histogram and calculate the mean and standard deviation. Do the means of each set of data come out close to each other?  Are the standard deviations of each set the same?  What is the standard error of the mean of each set?  Are the differences between the means of all the sets similar to the values of the calculated standard errors?**"]},{"metadata":{"id":"Z9q-Dh9I82p3","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"oYr1Jwxp82p5","colab_type":"text"},"cell_type":"markdown","source":["** Exercise 3: plot a histogram of the combined dataset (including all 100 measurements) and calculate the mean, standard deviation, and standard error of the mean. Compare this to the results from the individual datasets comprising 20 measurements. What is the difference? Write your combined dataset to a file (i.e. one column with 100 data points) and save your final histogram.**\n","\n","Hint: you can flatten a 2D-array into a 1D-array by using the <span style=\"color:blue\">flatten()</span> function. For example, the following line of code would flatten a (pre-existing) 2D array called 'data_array' and store it into a 1D array called 'new_1Darray':\n","\n","```python\n","new_1Darray = data_array.flatten()\n","```"]},{"metadata":{"id":"nqt4a5Tb82p6","colab_type":"code","colab":{},"outputId":"9c029722-47fc-4cc2-84ee-74c15e953a59"},"cell_type":"code","source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0 1 2 3]\n"],"name":"stdout"}]},{"metadata":{"id":"eUl1N44p82p-","colab_type":"text"},"cell_type":"markdown","source":["<div style=\"background-color: #00FF00\"> Show your recap exercise and discuss your findings with a demonstrator - and don't forget to note down your findings in your logbook!</div>"]},{"metadata":{"id":"4b1LYNAZ82qA","colab_type":"text"},"cell_type":"markdown","source":["## 3. Plotting error bars<a id=\"errorbars\"></a>\n","So far we have learnt to plot our data using linear plots, scatter plots, log plots, and histograms. However, normally all data we take will have errors associated with it. Our plots should include these errors in the form of error bars. Fortunately this is straightforward with matplotlib as it includes the function <span style=\"color:blue\">errorbar()</span> which creates a plot with error bars for us. \n","\n","** Exercise 4: have a look at the help for the <span style=\"color:blue\">errorbar()</span> function to see which input arguments it takes. Pay particular attention to the keywords <span style=\"color:blue\">yerr</span>, which takes an array that includes the y-error bars, and <span style=\"color:blue\">fmt</span>, with which you specify the plotting symbol. **\n","\n","** Exercise 5: load the resistivity data we used last session ([Resistivity.txt](Resistivity.txt)), create an array containing 5% errors on the resistivity data, and plot a scatter plot of the data including error bars. **"]},{"metadata":{"id":"tTkTzW4W82qA","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"4qReh98R82qD","colab_type":"text"},"cell_type":"markdown","source":["<div style=\"background-color: #FFF8C6\">\n","You can customise many features on your error bar plot. Can you find out how to put caps on your error bars (so they are displayed as **T** rather than **I**)? Also, your independent variable may have error bars too. Add fixed temperature error bars of 2K to your plot. "]},{"metadata":{"id":"sb1pvU9o82qE","colab_type":"text"},"cell_type":"markdown","source":["<div style=\"background-color: #FFF8C6\">\n","### Error bars on histograms\n","Sometimes we want to plot error bars on histograms. For example, if your histogram displays a number of counts of a certain value, you may want to add Poisson errors to each bin ($\\sigma_{\\rm Poisson} = \\sqrt{N}$, where $N$ is the number of counts in the bin).\n","\n","Below, recreate the histogram you made in the previous section of the full dataset, and add Poisson error bars to each bin. Tip: besides plotting a histogram, the matplotlib function <span style=\"color:blue\">hist()</span> can return values too. Look this up, and use it to calculate and create the error bars with the <span style=\"color:blue\">errorbar()</span> function. You will need to think carefully about the $x$-positions of the error bars!"]},{"metadata":{"id":"-FTL1cun82qF","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"qsszOHvB82qI","colab_type":"text"},"cell_type":"markdown","source":["## 4. Line fitting<a id=\"linefitting\"></a>\n","In the last session we had noticed that the resistivity data appears to show a linear relationship with temperature. In order to find this relationship, we want to fit a straight line to our data. We will do this by using the Scipy routine <span style=\"color:blue\">polyfit()</span>. This routine takes as arguments an array of the x values of the data, an array of the y values, and the *order* of the polynomial (what power of x) - in this case 1 for a straight line. We can then tell it to weight each data point by the inverse of its error with the <span style=\"color:blue\">w</span> keyword, and ask it to return the uncertainty of the fit parameters by setting <span style=\"color:blue\">cov=True</span>. \n","\n","The routine returns an array which contains the best fit values for the coefficients of the polynomial ($P[0]$ and $P[1]$) \n","\n","$$ f(x) = P[1] + P[0] x $$\n","\n","and a *covariance matrix* which contains the information on the errors on the fit parameters *i.e.* how well we have measured the slope ($P[0]$) and intercept ($P[1]$).\n","\n","$$ \\left( \n","\\begin{array}\n","\\ C_{00} & C_{10} \\\\\n"," C_{01} & C_{11} \n","\\end{array}\\right)$$\n","\n","We are interested in the diagonal elements of this matrix, where for instance the error on fit parameter 1 :\n","\n","$$\\sigma_{P[1]}=\\sqrt{C_{11}}$$\n","\n","The other two elements of the covariance matrix describe the covariance between the two different parameters, which is something we do not need to use for our error analysis.\n","\n","The code below returns the linear fit to the Aluminium resistivity data. Carefully look through this code and make sure you understand it."]},{"metadata":{"id":"LYEcBeY182qK","colab_type":"code","colab":{}},"cell_type":"code","source":["import scipy as sp\n","import matplotlib.pyplot as plt\n","\n","T,R_Cu,R_Al = sp.loadtxt('Resistivity.txt',unpack=True)# Read in the data\n","errors_Al = 0.05*R_Al# Calculate 5% errors\n","errors_Cu = 0.05*R_Cu\n","\n","# The line below stores the fit coefficients in the fit_Al variable, and the covariance matrix in the cov_Al variable.\n","# Note that the input arguments for polyfit() below are:\n","# (1) the independent variable (T)\n","# (2) the dependent variable (R_Al)\n","# (3) the order of the polynomial to be fitted (1)\n","# (4) the weights of each data point (w = 1/errors_Al)\n","# (5) whether or not to return the covariance matrix (cov = True)\n","fit_Al,cov_Al = sp.polyfit(T,R_Al,1,w=1/errors_Al,cov=True)\n","print('Aluminium fit coefficients')\n","print(fit_Al)\n","print('covariance matrix')\n","print(cov_Al)\n","\n","sig_0 = sp.sqrt(cov_Al[0,0]) #The uncertainty in the slope\n","sig_1 = sp.sqrt(cov_Al[1,1]) #The uncertainty in the intercept\n","\n","print('Slope = %.3e +/- %.3e' %(fit_Al[0],sig_0))# Note the %.3e forces the values to be printed in scientific notation with 3 decimal places.\n","print('Intercept = %.3e +/- %.3e' %(fit_Al[1],sig_1))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SvocoSVj82qM","colab_type":"text"},"cell_type":"markdown","source":["We can now use the convenient <span style=\"color:blue\">poly1d()</span> routine from the SciPy package, which takes the fit parameters returned by <span style=\"color:blue\">polyfit()</span> and returns a function which calculates the corresponding fit values at any given point. We then plot the linear fit on top of our data. "]},{"metadata":{"id":"1KgkIHVD82qO","colab_type":"code","colab":{}},"cell_type":"code","source":["import scipy as sp\n","import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","# Calculate the fit \n","pAl=sp.poly1d(fit_Al)\n","print('Aluminium polynomial')\n","print(pAl)\n","\n","# Create the original data figure with error bars\n","plt.grid()\n","plt.xlabel(\"Temperature (K)\") \n","plt.ylabel(\"Resistivity (Ohm m)\") \n","plt.title(\"Resistivity Plot\") \n","plt.errorbar(T,R_Cu,yerr=errors_Cu, fmt='o', mew=2, ms=3, capsize=4)\n","plt.errorbar(T,R_Al,yerr=errors_Al, fmt='o', mew=2, ms=3, capsize=4)\n","plt.legend([\"Copper\", \"Aluminium\"], loc=2 ) \n","plt.xticks(sp.arange(200, 400, 50))\n","\n","# Overlay the linear fit\n","# Note that we create the y-coordinates for the fit data points by calling pAl \n","# (which was the return value of poly1Dfit), with the x-coordinates stored in T as the input argument.\n","# Check what this does exactly by plotting the below with crosses as symbols, rather than a line!\n","plt.plot(T,pAl(T))\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X1my7TEW82qQ","colab_type":"text"},"cell_type":"markdown","source":["** Exercise 6: now we have created and plotted the linear fit to the Aluminium resistivity data, can you do the same for the Copper resistivity data? Your final output should be a scatter plot of the data including error bars and both linear fits. **"]},{"metadata":{"id":"D3s8efGj82qR","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"5NrlMwsE82qU","colab_type":"text"},"cell_type":"markdown","source":["You may remember you created a fit to the Copper resistivity data by hand in your third Measurement and Uncertainties tutorial. How do the values of the fit you just computed compare to the ones you retrieved from your manual fit? In particular calculating the errors on your fit values is a lot easier using a numerical routine than when you have to compute them by hand! "]},{"metadata":{"id":"Wq6hA2mh82qU","colab_type":"text"},"cell_type":"markdown","source":["<div style=\"background-color: #FFF8C6\">\n","### A further investigation into the impact of measurement uncertainties.\n","The data we have used so far has been nearly ideal: there is little variance around the linear fit. In practice, data is often a lot noisier, i.e. the measured data points will show more scatter around the fit. To illustrate this, have a look at the file [noisy_data.txt](noisy_data.txt), which includes a noisier set of measurements of the Aluminium resistivity. The file contains three columns: the temperature, the resistivity measurement, and an error on the measurement. Upon inspection of the file, you will notice that the measurement errors are variable; below we will investigate the impact of the size of the errors on the linear fit.\n","\n","Start by reading in the noisy data set, and plotting it (with error bars) below."]},{"metadata":{"id":"oJu_jkzL82qV","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"6h908f0682qX","colab_type":"text"},"cell_type":"markdown","source":["<div style=\"background-color: #FFF8C6\">\n","As you can see, the data points are clearly more scattered, although the linear relationship is still apparent. Below, create two fits to the data: one that weights each data point by the inverse of its error, and one that does not take the errors into account. Overplot both on your data plot."]},{"metadata":{"id":"s6iu11In82qY","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"c5kKVjo182qa","colab_type":"text"},"cell_type":"markdown","source":["<div style=\"background-color: #FFF8C6\">\n","You should now see that the unweighted fit tries to take all data points into account equally. However, the weighted fit takes into account that the third and last data points have large error bars and therefore creates a steeper fit to accommodate the points with small error bars. Investigate this further by manually adjusting the size of the uncertainties of individual data points. Can you predict how the fit will change?\n","\n","The work you have just done highlights the importance of assigning realistic uncertainty estimates to your datapoints. Note however that in reality you should not manually adjust the size of the error bars just to create the fit you want! You should always be able to justify the size of your uncertainty estimate - if all measurements were taken in a similar way they will usually have a similar absolute or fractional error."]},{"metadata":{"id":"VPW_uy3682qb","colab_type":"text"},"cell_type":"markdown","source":["### Practical example\n","\n","In your Measurements and Uncertainties tutorial you looked at an experiment where the resistance of a pair of identical resistors was to be found. In this experiment, a measurement was made of the voltage difference across the two resistors and the current running through them was also measured. The resistance of each resistor can be described by the equation:<p>\n","$$R= \\frac{1}{2}\\frac{V_1 −V_2}{I},$$<p>\n","where $V_1$ and $V_2$ are the voltages at the two ends of the resistors and $I$ is the current through them.\n","\n","Consider two approaches to finding the value of $R$:\n","\n","1. We take one measurement of each of $V_1$, $V_2$ and $I$ and accept the equipment manufacturer’s error estimates giving the following values: $V_1 = 6.9 \\pm 0.5 \\rm\\, V$, $V_2 = 0.7 \\pm 0.1 \\rm \\,V$ and $I = 0.43 \\pm 0.03\\rm\\, A$. Find a value for $R$ and its error $\\sigma_R$ using the appropriate methods for combining errors. Note: you used this method in your Measurement and Uncertainties tutorial! <p>\n","\n","2. We take a series of measurements of $V_1$, $V_2$ and $I$ with results as given in [Resistors.csv](Resistors.csv). Plot $(V_1 − V_2)$ against $I$ and use a linear fit to find $R$ and $\\sigma_R$.\n","\n","** Exercise 7: use both methods to calculate the resistance $R$ and its associated error. Do the two approaches give the same results?**"]},{"metadata":{"id":"7YWlY6EP82qb","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"YbHHSs8C82qe","colab_type":"text"},"cell_type":"markdown","source":["<div style=\"background-color: #00FF00\"> Show your linear fits and error bar plots to a demonstrator - and don't forget to note down your findings in your logbook!</div>"]},{"metadata":{"id":"WuIIDK2z82qf","colab_type":"text"},"cell_type":"markdown","source":["## 5. Non-linear fits<a id=\"nonlinear\"></a>\n","So far we have only considered fitting straight lines to a dataset. More complex relationships might require the relationship to be represented by e.g. a higher-order polynomial or an exponential function. In the following exercise we will try to fit a second-order polynomial to the atmospheric CO$_2$ concentration, which can be found in [CO2_data.csv](CO2_data.csv).\n","\n","** Exercise 8: read in the CO$_2$ data set and plot it.** "]},{"metadata":{"id":"sYVCbdIf82qf","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"CIJWq4El82qj","colab_type":"text"},"cell_type":"markdown","source":["The CO$_2$ concentration varies periodically; this is caused by the change in uptake of CO$_2$ by vegetation during the seasons. However, there is also a year-on-year increase in the CO$_2$ concentration. \n","\n","**Exercise 9: fit the trend with a straight line, and overplot the result.**"]},{"metadata":{"id":"yc5VWm2s82qk","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"vwDnkOJD82qm","colab_type":"text"},"cell_type":"markdown","source":["It doesn't look like a straight line is the appropriate fit to the trend. This is even more clearly seen when a residuals plot is created, which shows the data minus the fit. \n","\n","** Exercise 10: below, subtract the fitted values from the measured data points and show the residuals plot. Important note: store your residuals in a variable called 'residuals', for further use later on. **"]},{"metadata":{"id":"TZZa9hMQ82qn","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"kf440YKF82qp","colab_type":"text"},"cell_type":"markdown","source":["This show there is clearly further structure in the trend. We can use the <span style=\"color:blue\">polyfit()</span> function to fit a second order polynomial to the CO$_2$ concentration data. This will give a fit of the form:\n","\n","$$ f(x) = P[2] + P[1] x + P[0] x^2. $$\n","\n","Here $P[0]$, $P[1]$, and $P[2]$ are the fit parameters. \n","\n","** Exercise 11: fit a polynomial of a higher order to the data and recreate your data plot with the fit overplotted. Also recreate the residual plot. Which order of polynomial would you pick to fit the trend?**"]},{"metadata":{"id":"moNLNFrR82qp","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"udyi2ETt82qs","colab_type":"text"},"cell_type":"markdown","source":["If you plot your residuals as a line plot, you can see the periodic variability in the data. To test whether this really is a yearly cycle (as posed earlier), we are going to fit a sine function to the residuals, of the form:\n","\n","$$ f(x) = A\\sin{\\frac{2\\pi}{T}t+\\phi} $$\n","\n","Here $A$ is the amplitude, $T$ is the period, $t$ is time, and $\\phi$ is the phase offset of the sine function.\n","\n","There is no pre-built routine that fits a sine function; instead we have to use the generic <span style=\"color:blue\">curve_fit()</span> function which is in the scipy.optimize package. The <span style=\"color:blue\">curve_fit()</span> function allows us to define our own fit function. Below is the example code to create our sine function fit. Carefully read through the code before running it; note how the fit function is defined in a function that we have called <span style=\"color:blue\">my_sin</span>, and we have to specificy an initial guess for the fit parameters."]},{"metadata":{"id":"RDTnOTMb82qs","colab_type":"code","colab":{}},"cell_type":"code","source":["from scipy.optimize import curve_fit# Import the function curve_fit from the optimize package in Scipy\n","\n","year,CO2=sp.loadtxt('CO2_data.csv',skiprows=2, delimiter=',',unpack=True)# Load the data\n","\n","# This is the function we want to fit - you will learn how to create a function from scratch in the next session.\n","def my_sin(t, period, amplitude, phase):\n","    return amplitude*sp.sin(t * 2*sp.pi/period + phase)\n","\n","# Our initial guess for the parameters\n","guess_period = 1# Period in years\n","guess_amplitude = 2\n","guess_phase = sp.pi\n","\n","p0=[guess_period, guess_amplitude, guess_phase]# Array that of initial parameter values\n","\n","# now do the fit\n","# curve_fit arguments: \n","# 1. the name of the function to fit (my_sin)\n","# 2. the independent function values (year)\n","# 3. the dependent function values to be fitted (note that your residuals need to be stored in a variable named residuals!)\n","# 4. an array with the initial parameter values (p0 = p0)\n","fit = curve_fit(my_sin, year, residuals, p0=p0)\n","# The fit variable contains the optimized parameters as its first element, and the covariance matrix as its second element.\n","print('The fit parameters are: ',fit[0])\n","\n","# recreate the fitted curve using the optimized parameters\n","# The *fit[0] notation 'unpacks' the first element of the fit. It is the same as saying: \n","# fit[0][0], fit[0][1], fit[0][2] (each of which contains one of the optimized variables)\n","data_fit = my_sin(year, *fit[0])\n","\n","# Create a plot of the fit with the residuals overlaid.\n","plt.xlabel('Year')\n","plt.ylabel('Residuals')\n","plt.plot(year,data_fit)\n","plt.plot(year,residuals)\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fOuboblT82qw","colab_type":"text"},"cell_type":"markdown","source":["You can see that the peaks and troughs in the residuals are well matched by the fit (although our fit has a fixed amplitude whereas the residuals clearly are more variable). If you pay attention to the printed fit parameters, you will see that the fitted period is very close to 1, i.e. there is indeed a yearly cycle in the data. Our initial guess of a period of 1 year was very good, which allowed the fitting routine to find the optimized parameters rapidly and accurately. It is very important to have good starting values, otherwise the fit might make no sense at all. You often only notice this when you actually plot the fit on top of the data! \n","\n","** Exercise 12: our particular fit function is extremely sensitive to the starting value of the period: try and change the initial guess for the period in the code above and see what happens. What happens when you change the starting guess for the other fit parameters?**"]},{"metadata":{"id":"MRw-o7fR82qw","colab_type":"text"},"cell_type":"markdown","source":["<div style=\"background-color: #FFF8C6\">\n","Normally when we try and fit a function, we first decide what kind of function makes physical sense. When you expect a linear relationship, it is sensible to fit a straight line. In the data above however, we fitted a polynomial of arbitrary order to the trend, without a theoretical reason for it. In the case of the atmospheric CO$_2$ concentration, it is more common to fit an exponential curve (a good fit would then indicated \"exponential growth\"). Create an exponential fit to the trend by using the <span style=\"color:blue\">curve_fit()</span> function. To do this, first copy the <span style=\"color:blue\">my_sin</span> function from the code cell above, change its name to <span style=\"color:blue\">my_exp</span> and alter it to return a function of the form:\n","\n","$$f(x) = P[2] + P[1]e^{P[0]t}$$\n","\n","Here $P[0]$, $P[1]$, and $P[2]$ are the fit parameters, and $t$ is the time in years. Make sure your <span style=\"color:blue\">curve_fit()</span> function calls your new <span style=\"color:blue\">my_exp</span> function instead of <span style=\"color:blue\">my_sin</span>!\n","\n","Hint: subtract the starting year from your time array so that it starts at 1 instead of around 1960. Also, as you have seen when we tried to fit a sine function, the initial guess of the fit is very important. To make an educated guess of the initial parameters, first plot the data and your guess by hand so you can choose an offset and exponent that are at least of the right order of magnitude."]},{"metadata":{"id":"7hbCPJhs82qy","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"s3sfapjr82qz","colab_type":"text"},"cell_type":"markdown","source":["We have now fitted the CO$_2$ concentration data with a sine function to represent the yearly variability and a polynomial to represent the overall trend. The two fits added together are our best fit for the data as a whole. \n","\n","**Exercise 13: plot a graph of the full CO$_2$ concentration data with the total fit overlaid.**"]},{"metadata":{"id":"uFIgFvdI82q0","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ItFFrk2a82q2","colab_type":"text"},"cell_type":"markdown","source":["<div style=\"background-color: #00FF00\"> Show your trend fit, sine fit, total fit, and residual plots fit to a demonstrator - and don't forget to note down your findings in your logbook!</div>"]},{"metadata":{"collapsed":true,"id":"uVqGWeLX82q4","colab_type":"text"},"cell_type":"markdown","source":["### Example: scanning experiment fitting\n","The data below, contains what we think to be a Gaussian “feature” in a scanning experiment (it could be a spectral line in optics or a mass scan in particle physics or many other physical situations). This “feature” sits on top of a background. You can assume the background is linear, but not necessarily flat. "]},{"metadata":{"id":"PYehXVxu82q5","colab_type":"code","colab":{}},"cell_type":"code","source":["x = sp.array([ 100.,  101.,  102.,  103.,  104.,  105.,  106.,  107.,  108.,\n","        109.,  110.,  111.,  112.,  113.,  114.,  115.,  116.,  117.,\n","        118.,  119.,  120.,  121.,  122.,  123.,  124.,  125.,  126.,\n","        127.,  128.,  129.,  130.,  131.,  132.,  133.,  134.,  135.,\n","        136.,  137.,  138.,  139.,  140.,  141.,  142.,  143.,  144.,\n","        145.,  146.,  147.,  148.,  149.])\n","y = sp.array([ 49.62351587,  53.28471702,  70.91469338,  59.347993  ,\n","        68.14021339,  47.96831052,  46.27111237,  47.75670421,\n","        54.27684285,  49.79369344,  41.06072665,  43.95823631,\n","        47.32189537,  57.59658829,  45.18881389,  56.58866369,\n","        50.1240723 ,  42.6683265 ,  41.92068127,  25.85132307,\n","        46.60808952,  38.07772697,  56.7941344 ,  72.65808868,\n","        54.94790233,  84.97532661,  82.91663574,  54.97400141,\n","        33.05466879,  31.07916615,  30.20075973,  23.87661428,\n","        21.81024528,  28.83273888,  17.92903416,  27.57351836,\n","        25.05685919,  27.4866161 ,  31.13142432,  20.26710321,\n","        16.80327091,  14.1787744 ,  20.52320243,  22.65700337,\n","        16.23164708,  11.78551076,  15.21441115,  12.58749491,\n","        12.88956241,   6.24572757])\n","y_error = sp.array([ 7.74596669,  7.68114575,  7.61577311,  7.54983444,  7.48331477,\n","        7.41619849,  7.34846923,  7.28010989,  7.21110255,  7.14142843,\n","        7.07106781,  7.        ,  6.92820323,  6.85565464,  6.78233068,\n","        6.70821365,  6.63335528,  6.55833372,  6.48664491,  6.43341394,\n","        6.44498198,  6.61337546,  7.02586908,  7.63076491,  8.17847123,\n","        8.36660027,  8.05527104,  7.36400523,  6.58504642,  5.97802099,\n","        5.61585191,  5.42114516,  5.29873213,  5.1972821 ,  5.09915702,\n","        5.00001304,  4.89898045,  4.79583158,  4.69041576,  4.5825757 ,\n","        4.47213596,  4.35889894,  4.24264069,  4.12310563,  4.        ,\n","        3.87298335,  3.74165739,  3.60555128,  3.46410162,  3.31662479])\n","\n","plt.errorbar(x, y, y_error, fmt='o',capsize=2)\n","plt.xlabel('scan value')\n","plt.ylabel('signal')\n","plt.title('Scan experiment data')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"y4sqY9I882q7","colab_type":"text"},"cell_type":"markdown","source":["** Exercise 14: use the <span style=\"color:blue\">curve_fit()</span> function to fit a straight line for the background and a Gaussian function for the feature. Hence, find the amplitude and width of the Gaussian feature. Note that in this case it is not a good idea to fit the line first and afterwards the Gaussian from the residuals, as the Gaussian will influence the line fit. Instead, fit both background and the Gaussian feature at once.**\n","\n","This last exercise is challenging and integrates everything you have learnt about fitting so far. First write down in your log book what the function you want to fit would look like. Which are the parameters you need to fit? Remember to make a good first guess of the fitting parameters by closely the inspecting the plot above."]},{"metadata":{"id":"f_bMilxt82q7","colab_type":"text"},"cell_type":"markdown","source":["<div style=\"background-color: #FFF8C6\">\n","If you are feeling more adventurous, try reading this data from a pickle file. Pickle is a powerful and convenient way of storing Python objects in a file. You can view a short introduction to pickle [here](Pickle Intro.ipynb) and a pickle file of the data in [fit_data.pkl](fit_data.pkl)."]},{"metadata":{"id":"z8u4WNIO82q9","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"kVT-d_Ou82q_","colab_type":"text"},"cell_type":"markdown","source":["<div style=\"background-color: #00FF00\">Show your work to a demonstrator. </div>"]},{"metadata":{"id":"MvUyKtkL82q_","colab_type":"text"},"cell_type":"markdown","source":["<div style=\"background-color: #FFF8C6\">\n","\n","If you have time and already have lab data to fit, use Python to fit your data for you."]},{"metadata":{"id":"y0XogKCH82rB","colab_type":"text"},"cell_type":"markdown","source":["## Please complete the [Mentimeter Poll](https://www.menti.com/46d97b) for this session "]}]}